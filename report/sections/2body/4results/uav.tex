\section{Case Study 1: Unnamed Aerial Vehicle}

\subsection{First Model}

\subsubsection*{First Model Summary}

After the \gls*{nn} training, it was tested using the 200 samples, as the~\cref{tab:ann_parameters_uav}.
The metrics to evaluate the second model are shown in the~\cref{tab:model_summary_uav} and in the~\cref{fig:metrics_model_3}.
%
\begin{table}[!htb]
    \centering
    \caption{Model summary}
    \begin{tblr}{
        row{even}={light_color}
    }
    \toprule
    Parameter & Value \\
    \midrule
    MSE & 0.00085 \\
    MAE & 0.00746 \\
    \bottomrule
    \end{tblr}

    {\footnotesize Source: prepared by the author.}
    \label{tab:model_summary_uav}
\end{table}
%
\begin{figure}[!htb]
    \centering
    \caption[Loss function to the first model.]{Loss function to the first model.}
    \import{/home/gabriel/Documentos/deep-learning/report/figures/4results/uav}{metrics_model_3.pgf}

    {\footnotesize Source: prepared by the author.}
    \label{fig:metrics_model_3}
\end{figure}
% \begin{figure}[!htb]
%     \centering
%     \caption{Some caption}
%     \import{/home/gabriel/Documentos/deep-learning/report/figures/4results/uav/}{epochsxloss.pgf}
% \end{figure}

\subsubsection*{Comparison of the First Model with the Script}

The~\cref{fig:model_3_comparison} shows the comparison of the control torque from the script with the \gls*{nn} created model for the same \(\symbf{x}_s\).
%
\begin{figure}[!htb]
    \centering
    \caption[Comparing the first model with the script]{Comparing the first model with the script. The continuous curve is the control torque from the script, while dashed curve is the output from the \gls*{nn} model.}
    \import{/home/gabriel/Documentos/deep-learning/report/figures/4results/uav}{model_3_comparison.pgf}

    {\footnotesize Source: prepared by the author.}
    \label{fig:model_3_comparison}
\end{figure}

From the model statistics, the loss function for the test sample gave the result of 0.00085, which is an acceptable value for its purpose.
Although the~\cref{fig:model_3_comparison} looks like to show some discrepancy for \(U_2(t)\) and \(U_3(t)\), they do not mean the model did not predict precisely the control torque. 
After the first 10 seconds, which is the time that the \gls*{uav} is leaving the ground, the model is able to describe the control torque very well.

The major error, i.e., in the beginning of the motion may be caused by the interference of the \(z\)-axis trajectory. 
The discrepancy, actually, represents very little in the major context, since the image scale may distort the real values.
That said, other possible reason for the error in the model is the quantity of samples to make the training of the neural network. 
A thousand trajectories are not a good quantity for the model to make a good prediction.
To have an accurate model, it should have at least one hundred thousand trajectories, but due to the processing limitation, it was not possible.

Even though the model curve did not overlap the curve from the script, it gave the same pattern.

\subsection{Second Model}

The second model has the same parameters of the first model in terms of the \gls*{nn}.
The only difference between the two models are the input and the output data.
While in the first one both the input and output data were raw, the second one the data was normalized.

\begin{figure}[!htb]
    \centering
    \caption[Comparing the second model with the script]{Comparing the second model with the script. The continuous curve is the control torque from the script, while dashed curve is the output from the \gls*{nn} model.}
    \import{/home/gabriel/Documentos/deep-learning/report/figures/4results/uav}{model_4_comparison.pgf}

    {\footnotesize Source: prepared by the author.}
    \label{fig:model_4_comparison}
\end{figure}

The metrics to evaluate the second model are shown in the~\cref{tab:model_normalized_summary_uav} and in the~\cref{fig:metrics_model_4}.
%
\begin{table}[!htb]
    \centering
    \caption{Normalized model summary}
    \begin{tblr}{
        row{even}={light_color}
    }
    \toprule
    Parameter & Value \\
    \midrule
    MSE & 0.00001 \\
    MAE & 0.00025 \\
    \bottomrule
    \end{tblr}

    {\footnotesize Source: prepared by the author.}
    \label{tab:model_normalized_summary_uav}
\end{table}
%
\begin{figure}[!htb]
    \centering
    \caption[Loss function to the second model.]{Loss function to the second model.}
    \import{/home/gabriel/Documentos/deep-learning/report/figures/4results/uav}{metrics_model_4.pgf}

    {\footnotesize Source: prepared by the author.}
    \label{fig:metrics_model_4}
\end{figure}
Since the data is normalized, it is notable that the trained model could predict better when comparing to the previous model.
The data processing before passing to the training made the model perform at its best.
This happens because all the data is in a range from negative one to positive one, while the first model this range was very high, making it difficult to predict a