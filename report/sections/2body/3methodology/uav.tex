\section{Neural Network for Unnmaed Aerial Vehicle Control}

\subsection{Data Generation}

Since the script of \citet{geronel2023} provides the control torque \(\mathbf{\tau}\) as input and the state-space \(\mathbf{x}_s\) as output vector through dynamic and control equations, the \gls*{nn} goal developed is to go in the opposite direction, as a inverse function: take \(\mathbf{x}_s\) as the input vector and predict the \(\mathbf{\tau}_{\eta}\) vector as output.
Modifications in the script are minimal.
The time is a discrete vector with \SI{200}{s} and step 0.01, therefore the time vector has \(1\times 20001\) dimension.
The ``extra'' value of time is the zero value.

The output vector \(\mathbf{T}\) has \(20001\times 4\) dimension the and the input vector \(\mathbf{X}_s\) has  \(20001\times 12\) dimension:
%
\begin{align}
    \mathbf{T} &= \begin{bmatrix}
        U_1 & U_2 & U_3 & U_4 \\
        \vdots       & \vdots       & \vdots       & \vdots  \\
    \end{bmatrix} 
    \label{eq:tau_input} \\
    \setcounter{MaxMatrixCols}{13}
    \mathbf{X}_s &=
    \begin{bmatrix}
        x&y&z&\phi&\theta&\psi&\dot{x}&\dot{y}&\dot{z}&\dot{\phi}&\dot{\theta}&\dot{\psi} \\
        \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots 
    \end{bmatrix}
    \label{eq:xs_output}
\end{align}

Circular trajectory was arbitrary selected as starting point.
By a loop, it was generated 1000 different trajectories changing the position  by increasing 1/600  for each loop.

This way, it was generated one thousand input and output vector.
Both were stored in a \matlab variable and exported through the \texttt{.mat} extension to be used with TensorFlow inside Python environment.

\subsection{Neural Networks Overview}

The first approach for the \gls*{nn} is to use the raw data, both for input and output and do the training.
Even though it works, it does not give the proper result.
Therefore, the preprocessing of the data is mandatory to get the best results.
This way, all input and output data were normalized in order to get them all standardized.

The normalization is in L2 form, from the \emph{sklearn.preprocessing.normalize} function, applied in each matrix column.
From the trained \gls*{nn}, all input data should be normalized and naturally the output also will be normalized.
However, the control forces (output data) can not be normalized to be useful, but there is no ``denormalized'' correspondent matrix to the output data from the \gls*{nn}.

To solve this problem, a second \gls*{nn} was created to be able to denormalize the output data.
When preprocessing the data, as the normalization is done, both norms of the input and output data are stored and the second \gls*{nn} is made from them.
The~\cref{fig:nns_scheme} show how the data and the \glspl{nn} are related for the training. 
When the training and the validation is done, the ready-to-use model will perform as shown in the~\cref{fig:full_scheme} scheme.

\begin{figure}[!htb]
    \centering
    \caption[Data and neural networks relation]{Data and neural networks relation. The training data in the extremes are the ones generated by the white box parametric model.}
    \includesvg{figures/3methodology/nns_scheme.svg}

    {\footnotesize Source: prepared by the author.}
    \label{fig:nns_scheme}
\end{figure}

\begin{figure}[!htb]
    \centering
    \caption[Model in production]{Model in production. The scheme shows how the process returns the control forces from the state space.}
    \includesvg{figures/3methodology/full_scheme.svg}

    {\footnotesize Source: prepared by the author.}
    \label{fig:full_scheme}
\end{figure}

\subsection{Neural Network Modeling}

The \gls*{nn} 1 is responsible for, from the normalized state space, to return the normalized control forces, as shown in the~\cref{fig:nn1_scheme}.
The problem is considered as a regression problem, as the~\cref{eq:function_training_model_uav} shows. Input and output data are all matrices.
%
\begin{subequations}\label{eq:function_training_model_uav}
    \begin{align}
        &f\big(x,y,\ldots,\dot{\theta},\dot{\psi}\big) = \langle U_1, U_2, U_3, U_4 \rangle \\
        &f(\mathbf{X}_s) = \mathbf{T}
    \end{align}
\end{subequations}

\begin{figure}[!htb]
    \centering
    \caption[Schematic model of the neural network for the normalized data]{Schematic model of the neural network for the normalized data. The input layer receives every element of the \(\mathbf{x}_s\) and returns every element of \(\mathbf{\tau}\). There are two hidden layers, each one with 64 neurons.}
    \includesvg{./figures/3review/nn/nn2.svg}

    {\footnotesize Source: prepared by the author.}
    \label{fig:nn1_scheme}
\end{figure}

Characteristics of the \gls*{nn} 1 are provided in the~\cref{tab:nn1_char}.

\begin{table}[!htb]
    TABELA AQUI
    \label{tab:nn1_char}
\end{table}

\begin{figure}[!htb]
    \centering
    \caption[Schematic model of the neural network for the norms]{Schematic model of the neural network for the norms. The input data receives the state space norm and return the correspondent force control norm. There are two hidden layers, each one with 64 neurons.}
    \includesvg{./figures/3review/nn/nn4.svg}

    {\footnotesize Source: prepared by the author.}
\end{figure}