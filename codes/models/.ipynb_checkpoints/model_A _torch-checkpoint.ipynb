{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzf7tV6lb7Qt"
      },
      "source": [
        "# Model 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkzlvxPkb7Qy"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TMAG7ceYb7Qz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE: cuda\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "from sklearn.preprocessing import normalize\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"DEVICE: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading the MATLAB files.\n",
        "xs = loadmat('xs_all.mat')\n",
        "tau = loadmat('tau_all.mat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LoadXsTau(Dataset):\n",
        "\n",
        "    def __init__(self, xs: dict, tau: dict, normalize: bool = True) -> None:\n",
        "        super().__init__()\n",
        "        self.tau_all = tau['tau_all'].squeeze() \n",
        "        self.xs_all = xs['xs_all'].squeeze()\n",
        "        self.length = len(self.xs_all)\n",
        "        self.normalize = normalize\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        xs = self.xs_all[index]\n",
        "        tau = self.tau_all[index]\n",
        "\n",
        "        if self.normalize:\n",
        "            xs = normalize(xs, axis=0)\n",
        "            tau = normalize(tau, axis=0)\n",
        "\n",
        "        xs = torch.tensor(xs.T, dtype=torch.float32)\n",
        "        tau = torch.tensor(tau.T, dtype=torch.float32)\n",
        "\n",
        "        return xs, tau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lenght of train data: 25\n",
            "Lenght of test data: 7\n"
          ]
        }
      ],
      "source": [
        "dataset = LoadXsTau(xs, tau, normalize=True)\n",
        "train_data, test_data = torch.utils.data.random_split(dataset, [0.8, 0.2])\n",
        "\n",
        "train_dataloader= DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_dataloader= DataLoader(test_data, batch_size=32, shuffle=True)\n",
        "\n",
        "print(f\"Lenght of train data: {len(train_dataloader)}\")\n",
        "print(f\"Lenght of test data: {len(test_dataloader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelA(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(12, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 4)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ModelA(\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=12, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=128, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ModelA().to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # if batch % 400 == 0:\n",
        "        #     print(f\"Looked at {batch * len(X)}/{len(dataloader.dataset)} samples\")\n",
        "\n",
        "        return loss\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        test_pred = model(X)\n",
        "        test_loss = loss_fn(test_pred, y)\n",
        "\n",
        "    return test_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8efad8ad5aa542c9a9671b4f580136a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 1\n",
            "Epoch: 0 | Train loss: 0.00247, Test loss: 0.00146\n",
            "--------------------------------------------------\n",
            "EPOCH 21\n",
            "Epoch: 20 | Train loss: 0.00147, Test loss: 0.00136\n",
            "--------------------------------------------------\n",
            "EPOCH 41\n",
            "Epoch: 40 | Train loss: 0.00208, Test loss: 0.00237\n",
            "--------------------------------------------------\n",
            "EPOCH 61\n",
            "Epoch: 60 | Train loss: 0.00349, Test loss: 0.00214\n",
            "--------------------------------------------------\n",
            "EPOCH 81\n",
            "Epoch: 80 | Train loss: 0.00275, Test loss: 0.00419\n",
            "--------------------------------------------------\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "loss_overall = []\n",
        "loss_overall_test = []\n",
        "\n",
        "for epoch in tqdm(range(epochs), leave=False):\n",
        "    loss = train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loss = test(test_dataloader, model, loss_fn)\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"EPOCH {epoch+1}\")\n",
        "        print(f\"Epoch: {epoch} | Train loss: {loss:.5f}, Test loss: {test_loss:.5f}\")\n",
        "        print(\"-\"*50)\n",
        "    loss_overall.append(loss.item())\n",
        "    loss_overall_test.append(test_loss.item())\n",
        "    \n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib ipympl\n",
        "t = np.linspace(1, epochs, epochs)\n",
        "\n",
        "plt.plot(t, loss_overall, label='Train loss')\n",
        "plt.plot(t, loss_overall_test, label='Test loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
